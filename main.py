import os
import asyncio
import json
import logging
import re
from typing import AsyncGenerator
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import httpx
from duckduckgo_search import DDGS

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("FinalPerfectAnalyzer")

# API í‚¤ (í™˜ê²½ë³€ìˆ˜)
GEMINI_KEY = os.environ.get("GEMINI_API_KEY", "")
GROQ_KEY = os.environ.get("GROQ_API_KEY", "")
OPENROUTER_KEY = os.environ.get("OPENROUTER_KEY", "")
SERPER_KEY = os.environ.get("SERPER_API_KEY", "")

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Reddit ë“±ì˜ ì°¨ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•´ User-Agent ì„¤ì •
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    }
    app.state.client = httpx.AsyncClient(timeout=30.0, headers=headers, follow_redirects=True)
    yield
    await app.state.client.aclose()

app = FastAPI(lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# --- ìœ í‹¸ë¦¬í‹°: HTML ì •ì œ ---
def clean_content(text: str) -> str:
    if not text: return ""
    # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
    text = re.sub(r'<(script|style|header|footer|nav|form|iframe|noscript).*?>.*?</\1>', '', text, flags=re.DOTALL)
    text = re.sub(r'<[^>]+>', ' ', text)
    return " ".join(text.split())[:10000]

# --- í•µì‹¬: ë©€í‹° ì†ŒìŠ¤ ê²€ìƒ‰ ë¡œì§ (Serper + Reddit + DDG) ---
async def get_all_urls(client: httpx.AsyncClient, product: str) -> list:
    urls = []
    
    # 1. Serper (Google Search) - ê°€ì¥ í’ˆì§ˆ ì¢‹ìŒ
    if SERPER_KEY:
        try:
            r = await client.post("https://google.serper.dev/search", 
                headers={"X-API-KEY": SERPER_KEY, "Content-Type": "application/json"},
                json={"q": f"{product} ì‹¤ì‚¬ìš© í›„ê¸° ì¥ì  ë‹¨ì ", "num": 5})
            if r.status_code == 200:
                urls.extend([item['link'] for item in r.json().get('organic', [])])
        except Exception as e: logger.error(f"Serper Error: {e}")

    # 2. Reddit ì „ìš© ê²€ìƒ‰ (Redditì€ ë³„ë„ì˜ í—¤ë”ì™€ ì¿¼ë¦¬ í•„ìš”)
    try:
        with DDGS() as ddgs:
            # ë˜ë”§ ê²°ê³¼ë§Œ ë”°ë¡œ ìˆ˜ì§‘
            reddit_res = await asyncio.to_thread(lambda: list(ddgs.text(f"{product} review site:reddit.com", max_results=3)))
            urls.extend([r['href'] for r in reddit_res if 'href' in r])
    except Exception as e: logger.error(f"Reddit Search Error: {e}")

    # 3. DuckDuckGo ì¼ë°˜ ê²€ìƒ‰ (ë°±ì—…)
    try:
        with DDGS() as ddgs:
            ddg_res = await asyncio.to_thread(lambda: list(ddgs.text(f"{product} ì‹¤ì‚¬ìš© ë‹¨ì ", max_results=4)))
            urls.extend([r['href'] for r in ddg_res if 'href' in r])
    except Exception as e: logger.error(f"DDG Error: {e}")

    return list(set(urls)) # ì¤‘ë³µ ì œê±°

# --- ì‹¤ì‹œê°„ ë¶„ì„ ìŠ¤íŠ¸ë¦¼ ì—”ì§„ ---
async def main_engine(product: str) -> AsyncGenerator[str, None]:
    client = app.state.client
    try:
        # [Step 1] ê²€ìƒ‰ ì‹œì‘ (20%)
        yield f"data: {json.dumps({'p': 20, 'm': 'ğŸŒ Google, Redditì—ì„œ ë¦¬ë·° ì†ŒìŠ¤ë¥¼ íƒìƒ‰ ì¤‘ì…ë‹ˆë‹¤...'})}\n\n"
        target_urls = await get_all_urls(client, product)
        
        if not target_urls:
            raise Exception("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # [Step 2] ë°ì´í„° ìˆ˜ì§‘ (50%)
        yield f"data: {json.dumps({'p': 50, 'm': f'ğŸ“¦ {len(target_urls)}ê°œì˜ ì†ŒìŠ¤ì—ì„œ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ê³  ê´‘ê³ ë¥¼ ì œê±° ì¤‘ì…ë‹ˆë‹¤...'})}\n\n"
        
        # ë³‘ë ¬ ìˆ˜ì§‘
        tasks = [client.get(url, timeout=12.0) for url in target_urls]
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        valid_texts = []
        for i, res in enumerate(responses):
            if isinstance(res, httpx.Response) and res.status_code == 200:
                valid_texts.append(f"[ì¶œì²˜ {i+1}]: {clean_content(res.text)}")
        
        context = "\n\n".join(valid_texts)

        # [Step 3] AI ë¶„ì„ ë¡œí…Œì´ì…˜ (80%)
        yield f"data: {json.dumps({'p': 80, 'm': 'ğŸ§  AI ëª¨ë¸(Gemini/Groq/OpenRouter)ì„ ì—°ê²°í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...'})}\n\n"
        
        final_answer = ""
        used_model = ""
        prompt = f"ì œí’ˆ '{product}'ì— ëŒ€í•œ ì‹¤ì‚¬ìš©ìë“¤ì˜ ì§„ì§œ ì¥ë‹¨ì ì„ ìš”ì•½í•´ì¤˜. ì¸í„°ë„· ê´‘ê³ ê¸€ì€ ë¬´ì‹œí•˜ê³ , ì‹¤ì œ ë¶ˆë§Œì‚¬í•­ê³¼ ì¹­ì°¬ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•´ì„œ 1~10ì  í‰ì ê³¼ í•¨ê»˜ ë¦¬í¬íŠ¸ë¡œ ì¨ì¤˜.\n\në°ì´í„°:\n{context}"

        # --- AI ë¡œí…Œì´ì…˜ ì‹œë„ ---
        # 1. Gemini
        if GEMINI_KEY:
            try:
                g_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"
                r = await client.post(g_url, json={"contents": [{"parts": [{"text": prompt}]}]})
                if r.status_code == 200:
                    final_answer = r.json()['candidates'][0]['content']['parts'][0]['text']
                    used_model = "Gemini 1.5 Flash"
            except: pass

        # 2. Groq (ë°±ì—…)
        if not final_answer and GROQ_KEY:
            try:
                r = await client.post("https://api.groq.com/openai/v1/chat/completions",
                    headers={"Authorization": f"Bearer {GROQ_KEY}"},
                    json={"model": "llama3-70b-8192", "messages": [{"role": "user", "content": prompt}]})
                if r.status_code == 200:
                    final_answer = r.json()['choices'][0]['message']['content']
                    used_model = "Groq (Llama 3)"
            except: pass
            
        # 3. OpenRouter (ìµœì¢… ë°±ì—…)
        if not final_answer and OPENROUTER_KEY:
            try:
                r = await client.post("https://openrouter.ai/api/v1/chat/completions",
                    headers={"Authorization": f"Bearer {OPENROUTER_KEY}"},
                    json={"model": "deepseek/deepseek-chat", "messages": [{"role": "user", "content": prompt}]})
                if r.status_code == 200:
                    final_answer = r.json()['choices'][0]['message']['content']
                    used_model = "OpenRouter (DeepSeek)"
            except: pass

        if not final_answer:
            raise Exception("ëª¨ë“  AI ëª¨ë¸ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # [Step 4] ì™„ë£Œ (100%)
        yield f"data: {json.dumps({'p': 100, 'm': f'âœ… {used_model} ë¶„ì„ ì™„ë£Œ!', 'answer': final_answer})}\n\n"

    except Exception as e:
        logger.error(f"Error: {e}")
        yield f"data: {json.dumps({'p': 0, 'm': f'âŒ ì˜¤ë¥˜: {str(e)}', 'error': True})}\n\n"

@app.get("/analyze")
async def analyze(product: str):
    return StreamingResponse(main_engine(product), media_type="text/event-stream")
