import os
import asyncio
import json
import logging
import re
from typing import AsyncGenerator, List
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import httpx
from duckduckgo_search import DDGS
from bs4 import BeautifulSoup  # HTML íŒŒì‹± ì•ˆì •í™”

# --- ë¡œê¹… ë° ì„¤ì • ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("UltimateAnalyzer")

# API í‚¤ ì„¤ì •
GEMINI_KEY = os.environ.get("GEMINI_API_KEY", "")
GROQ_KEY = os.environ.get("GROQ_API_KEY", "")
OPENROUTER_KEY = os.environ.get("OPENROUTER_KEY", "")
SERPER_KEY = os.environ.get("SERPER_API_KEY", "")

@asynccontextmanager
async def lifespan(app: FastAPI):
    limits = httpx.Limits(max_keepalive_connections=10, max_connections=20)
    app.state.client = httpx.AsyncClient(timeout=30.0, limits=limits, follow_redirects=True)
    yield
    await app.state.client.aclose()

app = FastAPI(lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# --- ë°ì´í„° ì •ì œ ---
def clean_html(raw_html: str) -> str:
    """HTML íƒœê·¸ ì œê±° ë° í•µì‹¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if not raw_html:
        return ""
    try:
        soup = BeautifulSoup(raw_html, "html.parser")
        for tag in soup(["script", "style", "header", "footer", "nav", "form", "iframe", "noscript"]):
            tag.decompose()
        text = soup.get_text(separator=" ")
        return " ".join(text.split())[:12000]
    except Exception as e:
        logger.error(f"HTML ì •ì œ ì˜¤ë¥˜: {e}")
        return raw_html[:2000]

# --- ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ ---
async def fetch_search_results(client: httpx.AsyncClient, query: str) -> List[str]:
    urls = []
    # 1. Serper
    if SERPER_KEY:
        try:
            resp = await client.post(
                "https://google.serper.dev/search",
                headers={"X-API-KEY": SERPER_KEY, "Content-Type": "application/json"},
                json={"q": query, "num": 5}
            )
            if resp.status_code == 200:
                urls.extend([r.get("link") for r in resp.json().get("organic", []) if r.get("link")])
        except Exception as e:
            logger.error(f"Serper Error: {e}")

    # 2. DuckDuckGo
    try:
        with DDGS() as ddgs:
            ddg_results = await asyncio.to_thread(lambda: list(ddgs.text(query, max_results=5)))
            urls.extend([r.get("href") for r in ddg_results if r.get("href")])
    except Exception as e:
        logger.error(f"DDG Error: {e}")

    # 3. Reddit
    try:
        reddit_query = f"{query} site:reddit.com"
        with DDGS() as ddgs:
            reddit_results = await asyncio.to_thread(lambda: list(ddgs.text(reddit_query, max_results=3)))
            urls.extend([r.get("href") for r in reddit_results if r.get("href")])
    except Exception as e:
        logger.error(f"Reddit Search Error: {e}")

    return list(set(urls))

# --- ì‹¤ì‹œê°„ ë¶„ì„ ì—”ì§„ ---
async def final_analysis_stream(product_name: str) -> AsyncGenerator[str, None]:
    client = app.state.client
    try:
        # ë‹¨ê³„ 1
        yield f"data: {json.dumps({'p': 20, 'm': 'ğŸŒ ê²€ìƒ‰ ì¤‘...'})}\n\n"
        search_query = f"{product_name} ì‹¤ì‚¬ìš© ë‹¨ì  ì¥ì  í›„ê¸°"
        target_urls = await fetch_search_results(client, search_query)
        if not target_urls:
            raise Exception("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

        # ë‹¨ê³„ 2
        yield f"data: {json.dumps({'p': 50, 'm': f'ğŸ“¦ {len(target_urls)}ê°œ ì†ŒìŠ¤ ìˆ˜ì§‘ ì¤‘...'})}\n\n"
        semaphore = asyncio.Semaphore(5)  # ë™ì‹œ ìš”ì²­ ì œí•œ

        async def safe_fetch(url):
            async with semaphore:
                try:
                    resp = await client.get(url, timeout=15.0)
                    if resp.status_code == 200:
                        return clean_html(resp.text)
                except Exception as e:
                    logger.error(f"Fetch Error {url}: {e}")
                return ""

        contexts = await asyncio.gather(*[safe_fetch(url) for url in target_urls])
        full_context = "\n\n".join([c for c in contexts if c])

        # ë‹¨ê³„ 3
        yield f"data: {json.dumps({'p': 80, 'm': 'ğŸ§  AI ë¶„ì„ ì¤‘...'})}\n\n"
        final_answer, model_used = None, ""
        prompt = f"ì œí’ˆ '{product_name}' ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•´ë¼. ê´‘ê³  ì œì™¸, ì¥ì /ë‹¨ì  êµ¬ë¶„.\n\në°ì´í„°:\n{full_context}"

        # Gemini
        if not final_answer and GEMINI_KEY:
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"
                r = await client.post(url, json={"contents": [{"parts": [{"text": prompt}]}]})
                if r.status_code == 200:
                    data = r.json()
                    final_answer = (
                        data.get("candidates", [{}])[0]
                        .get("content", {})
                        .get("parts", [{}])[0]
                        .get("text", "")
                    )
                    model_used = "Gemini 1.5 Flash"
            except Exception as e:
                logger.error(f"Gemini Error: {e}")

        # Groq
        if not final_answer and GROQ_KEY:
            try:
                r = await client.post(
                    "https://api.groq.com/openai/v1/chat/completions",
                    headers={"Authorization": f"Bearer {GROQ_KEY}"},
                    json={"model": "llama3-70b-8192", "messages": [{"role": "user", "content": prompt}]}
                )
                if r.status_code == 200:
                    data = r.json()
                    final_answer = (
                        data.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content", "")
                    )
                    model_used = "Groq (Llama 3)"
            except Exception as e:
                logger.error(f"Groq Error: {e}")

        if not final_answer:
            raise Exception("AI ëª¨ë¸ ì‘ë‹µ ì—†ìŒ")

        # ë‹¨ê³„ 4
        yield f"data: {json.dumps({'p': 100, 'm': f'âœ… {model_used} ë¶„ì„ ì™„ë£Œ!', 'answer': final_answer})}\n\n"

    except Exception as e:
        logger.error(f"Fatal Error: {str(e)}")
        yield f"data: {json.dumps({'p': 0, 'm': f'âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}', 'error': True})}\n\n"

@app.get("/analyze")
async def analyze_endpoint(product: str):
    return StreamingResponse(final_analysis_stream(product), media_type="text/event-stream")
